Investigating the Behavior of a Function Near a Singularity

This project studies the behavior of the function

ğ¹
(
â„
)
=
ğ‘’
âˆ’
â„
2
âˆ’
1
â„
2
F(h)=
h
2
e
âˆ’h
2
âˆ’1
	â€‹


for small, positive values of $h$.
Although the function is undefined at $h = 0$ due to division by zero, its limit exists and is meaningful.

The investigation is divided into two main phases:

Phase 1: Numerical exploration

Phase 2: Analytical verification

Phase 1 â€” Numerical Exploration and Limit Estimation

The goal of this phase is to understand the behavior of $F(h)$ empirically.

1. Computational Implementation

A script computes $F(h)$ for a carefully chosen sequence of decreasing values approaching zero:

â„
=
10
âˆ’
1
,
10
âˆ’
2
,
10
âˆ’
3
,
â€¦
,
10
âˆ’
16
h=10
âˆ’1
,10
âˆ’2
,10
âˆ’3
,â€¦,10
âˆ’16
2. Visualization and Trend Analysis

The computed values are plotted, typically with a logarithmic scale on the $h$-axis.

As $h$ decreases, $F(h)$ converges toward a finite limit.

This provides a numerical estimate of the limit:

ğ¿
=
lim
â¡
â„
â†’
0
ğ¹
(
â„
)
L=
hâ†’0
lim
	â€‹

F(h)
3. Identifying Numerical Instability

For very small $h$ (typically $h < 10^{-8}$), the computation breaks down due to catastrophic cancellation:

Cause:

The numerator $e^{-h^2} - 1$ subtracts two numbers extremely close to 1.

Finite-precision arithmetic wipes out significant digits, leaving mostly rounding errors.

Effect:

Dividing this tiny (and inaccurate) numerator by the even smaller denominator $h^2$ amplifies rounding errors.

Computed values deviate wildly from the true trend, sometimes returning $0$.

Key takeaway: Numerical computations have precision limits, especially near singularities.

Phase 2 â€” Analytical Solution and Convergence Rate

This phase transitions from numerical approximations to exact analysis.

1. Analytical Limit Calculation

Using the Taylor series expansion for $e^{-h^2}$:

ğ‘’
âˆ’
â„
2
=
1
âˆ’
â„
2
+
â„
4
2
âˆ’
â€¦
e
âˆ’h
2
=1âˆ’h
2
+
2
h
4
	â€‹

âˆ’â€¦

Substituting into $F(h)$:

	
ğ¹
(
â„
)
	
=
(
1
âˆ’
â„
2
+
â„
4
2
âˆ’
â€¦
â€‰
)
âˆ’
1
â„
2
		
	
	
=
âˆ’
â„
2
+
â„
4
2
âˆ’
â€¦
â„
2
		
	
	
=
âˆ’
1
+
â„
2
2
âˆ’
â€¦
		
F(h)
	â€‹

=
h
2
(1âˆ’h
2
+
2
h
4
	â€‹

âˆ’â€¦)âˆ’1
	â€‹

=
h
2
âˆ’h
2
+
2
h
4
	â€‹

âˆ’â€¦
	â€‹

=âˆ’1+
2
h
2
	â€‹

âˆ’â€¦
	â€‹

	â€‹


Taking the limit as $h \to 0$:

ğ¿
=
lim
â¡
â„
â†’
0
ğ¹
(
â„
)
=
âˆ’
1
L=
hâ†’0
lim
	â€‹

F(h)=âˆ’1
	â€‹

2. Error Quantification and Convergence Rate

With the exact value $L = -1$, we measure how fast $F(h)$ approaches its limit.

Absolute error:

ğ¸
(
â„
)
=
âˆ£
ğ¹
(
â„
)
âˆ’
ğ¿
âˆ£
=
âˆ£
ğ¹
(
â„
)
+
1
âˆ£
E(h)=âˆ£F(h)âˆ’Lâˆ£=âˆ£F(h)+1âˆ£

From the series expansion:

ğ¹
(
â„
)
=
ğ¿
+
â„
2
2
+
ğ‘‚
(
â„
4
)
F(h)=L+
2
h
2
	â€‹

+O(h
4
)

Thus, for small $h$:

ğ¸
(
â„
)
â‰ˆ
â„
2
2
E(h)â‰ˆ
2
h
2
	â€‹


On a log-log plot of $E(h)$ vs. $h$, the slope of the straight-line region gives the order of convergence $p$:

ğ¸
(
â„
)
âˆ
â„
ğ‘
E(h)âˆh
p

From the series expansion:

ğ‘
=
2
p=2
	â€‹

Key Insights

Limit Resolution of an Indeterminate Form

lim
â¡
â„
â†’
0
ğ‘’
âˆ’
â„
2
âˆ’
1
â„
2
=
âˆ’
1
hâ†’0
lim
	â€‹

h
2
e
âˆ’h
2
âˆ’1
	â€‹

=âˆ’1

Numerical Pitfalls
Demonstrates catastrophic cancellation and highlights floating-point limitations.

Error Analysis
Quantifies the discrepancy between computed and exact results.

Order of Convergence
Confirms that $F(h)$ converges toward its limit with order:

ğ‘
=
2
p=2
	â€‹
